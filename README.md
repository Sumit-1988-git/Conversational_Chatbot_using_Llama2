# Llama-2 7B Chatbot

## Introduction

In this mini project, we will explore **Llama-2 7B**, a powerful model fine-tuned for generating text and engaging in conversational AI.

By the end of this project, you'll be able to interact with the model and generate conversational responses. Whether you're curious about chatbot technology or simply want to see how machine-generated responses work, this project will guide you through the process.

## Objectives

- **Understand Llama-2 7B**: Gain an in-depth understanding of the Llama-2 7B model and its capabilities for conversational AI.
- **Interact with the Model**: Learn how to interact with the Llama-2 model by providing prompts and generating responses.
- **Integrate AI into Python**: Implement the Llama-2 7B model into Python applications using the Hugging Face Transformers library.
- **Create an Interactive Chatbot**: Set up an interactive environment where users can chat with the model in real-time.
  
## Workflow

The steps involved in this project are as follows:

1. **Installations**: Set up the required libraries.
2. **Prerequisites**: Ensure access to the Llama-2 7B model on Hugging Face.
3. **Loading the Model & Tokenizer**: Retrieve the model and tokenizer for your session.
4. **Creating the Llama Pipeline**: Set up the model for generating responses.
5. **Interacting with Llama**: Use prompts to interact with the model and explore its capabilities.

## Project Structure

Llama-2 7B Chatbot/

│

├── README.md # Project overview, setup, and instructions

├── Conversational_Chatbot_LLaMa_2.ipynb # Jupyter notebook containing the chatbot implementation

└── requirements.txt # List of dependencies for the project

## Tools and Libraries

The following tools and libraries are used in this project:

### **Tools**
- **Jupyter Notebook/Colab**: For creating and running interactive notebooks that showcase the Llama-2 7B model in action.
- **Hugging Face**: Provides the pre-trained Llama-2 model and tokenizer, and access to the Hugging Face platform for easy integration of transformers in Python.

### **Libraries**
- **transformers**: The Hugging Face Transformers library allows easy access to pre-trained models, including Llama-2 7B.

## Setup Instructions


### Step 1: Change Runtime to GPU

Ensure that the runtime is set to GPU for optimal performance.

You can experiment with Llama-2 7B Chat here:  
[Llama-2 7B Chat on Hugging Face](https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat)

### Step 2: Install Dependencies

### Step 3: Prerequisites - Hugging Face Authentication

### Step 4: Loading the Model \& Tokenizer

### Step 5: Creating the Llama Pipeline

### Step 6: Getting Responses

### Step 7: Making it Conversational



## Sample Prompts

Here are some example prompts you can try with the chatbot:

* 'I love playing online games like Counterstrike. Do you have any recommendations I might like?'
* "I'm a programmer and Python is my favorite language because of its simple syntax and variety of applications I can build with it. Based on that, what language should I learn next? Give me 5 recommendations"
* 'I liked "Game of Thrones" and "Shadow hunters". Do you have any recommendations of other shows I might like?'
