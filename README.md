# Llama-2 7B Chatbot



## Introduction

In this mini project, we explore **Llama-2 7B**, a model fine-tuned for generating text and engaging in conversational AI.

By the end of this project, you’ll be able to interact with the model and generate conversational responses.

Whether you're curious about chatbot technology or simply want to see a machine-generated response to specific questions, this will serve as a comprehensive guide.



## Workflow

1. **Installations**: We’ll begin by setting up the required libraries.
2. **Prerequisites**: Ensure you have access to the Llama-2 7B model on Hugging Face.
3. **Loading the Model \& Tokenizer**: Retrieve the model and tokenizer for the session.
4. **Creating the Llama Pipeline**: Set up the model for generating responses.
5. **Interacting with Llama**: Use prompts to interact with the model and explore its capabilities.



## Setup Instructions



### Step 1: Change Runtime to GPU

Ensure that the runtime is set to GPU for optimal performance.

You can experiment with Llama-2 7B Chat here:  
[Llama-2 7B Chat on Hugging Face](https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat)

### Step 2: Install Dependencies

### Step 3: Prerequisites - Hugging Face Authentication

### Step 4: Loading the Model \& Tokenizer

### Step 5: Creating the Llama Pipeline

### Step 6: Getting Responses

### Step 7: Making it Conversational



## Sample Prompts

Here are some example prompts you can try with the chatbot:

* 'I love playing online games like Counterstrike. Do you have any recommendations I might like?'
* "I'm a programmer and Python is my favorite language because of its simple syntax and variety of applications I can build with it. Based on that, what language should I learn next? Give me 5 recommendations"
* 'I liked "Game of Thrones" and "Shadow hunters". Do you have any recommendations of other shows I might like?'
